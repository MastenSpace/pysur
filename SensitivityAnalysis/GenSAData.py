#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
    Copyright 2017 Masten Space Systems, Inc.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

    Author: Jack Nelson <jnelson@masten.aero>
    
================================================

Functions to run sensitivity analysis on surrogate models and plot the results.

OVERVIEW
==========
This module provides functions to run variance-based sensitivity analysis on surrogate models generated with surrogate_modeler.py.
For a detailed overview of variance-based sensitivity analysis, see https://en.wikipedia.org/wiki/Variance-based_sensitivity_analysis.
From here on out, we'll refer to variance-based sensitivity analysis as just sensitivity analysis, or SA.

In brief, the purpose of sensitivty analysis is to test how the uncertainty in a model's outputs can be apportioned
to uncertainty in the model's inputs. The goal of sensitivty analysis in our case is to understand how the input 
parameters or combination of input parameters effects the output parameters. This is accomplished using Saltelli
variance-based sensitivity analysis tools from SALib.

The central function in this module is run_sensitivity_analysis(), which, as the name suggests, does the core work of 
running the sensitivity analysis on our surrogate model(s). This function loads previously-generated surrogate models from the file 
specified by model_file in the project root config. N samples of the model input parameters are generated 
for the sensitivity analysis. The number of samples to be generated is passed in as an argument to
run_sensitivity_analysis(), but defaults to 1e4 samples. The ranges across which samples are generated for each input parameter
is set in a text file specified by param_file in the root config. For an example of a parameter range file, see DB10_ParamRanges.txt.
From the input parameter samples, a sobol variance sensitivity analysis problem is formulated and solved, returning SAData, a dictionary 
of lists of the following sensitivity analysis products. Where P is the number of input parameters, SAData has the following fields:

    'S1' - First order sensitivities for each input. List of length P.
    'S1_conf' - Confidence intervals for each first-order sensitivity. List of length P.
    'S2' - Second order sensitivities for each combination of inputs (if enabled). List of length P^2.
    'S2_conf' - Confidence intervals for each second-order sensitivity (if enabled). List of length P^2.
    'ST' - Total sensitivities for each input. List of length P.
    'ST_conf' - Confidence intervals for each total sensitivity. List of length P.

Each field of the SAData dictionary contains a list of sensitivites or confidences. For S1, S1_conf, ST, and ST_conf, this is
a list of length P, where P is the number of parameters. For S2 and S2_conf, this is a list of length P^2, one for each combination
of the parameters.

Beacause a sensitivity analysis is run for each surrogate model loaded from the model_file, the SAData for each model is kept in
a list called SA_list that is returned at the end of run_sensitivity_analysis(). Each SAData is written to a pickle file for easy loading by 
another program, and a csv file for easy viewing by a human meatbag.

The next most important function in this module is plot_S1(), which takes a list of SAData objects, so essentially the output of
run_sensitivity_analysis(), and produces a pie chart of the first order sensitivities of each SAData result. These plots show the
relative proportion of the effect each input to the model has on the variance of the model's output. In other words, the pie charts
of the sensitivity analysis data shows which inputs most effect the outputs of our surrogate model.

USAGE
==========
Generating sensitivities and visualizing them with plot_S1() has a few pre-requisites:

- pre-requisites - It is assumed that the following things have already been done:
    - Surrogate models have been generated with surrogate_modeler.py and saved to a pickle file.
    - The output data MinMaxScaler objects generated by surrogate_modeler.py are saved to a pickle file.
    - The surrogate model and data scaler pickle file names are specified by model_file and scaler_file in the root config.
    - A parameter range text file has been created, and param_file in the root config is set to the name of the file 
      (see DB10_ParamRanges.txt for an example of what this file should look like).

The modules __main__ top-level script environment is set to automatically run the sensitivity analysis and plot the 
first-order sensitivities as configured in the root config. ALL TOP-LEVEL CONFIGURATION IS DONE IN THE ROOT CONFIG
\"SENSITIVITY ANALYSIS CONFIG\" FIELD. Once the root config has been configured, you simply run $ ./GenSAData.py from
a shell.

"""
import sys
import os
from itertools import izip
import pickle
import datetime as dt
import csv
import math

from SALib.sample import saltelli
from SALib.analyze import sobol
from sklearn import preprocessing
from sklearn.svm import SVR

import numpy as np
################################# USER INPUTS #################################
model_from_file = True

# outputs
output_dir = 'SA_outputs/'

# get the absolute path to config file
thispath = os.path.dirname(os.path.abspath(__file__))
config_relative_path = "/../"
sys.path.append(thispath + config_relative_path)

# choose the root config file to use
import config
###############################################################################

def write_second_order_analysis():
    """
        Takes first order, second order, and total sensitivity analysis results and formats them in series
        of matrices that can be written to a csv or pickle file.
    """


def load_surrogate_models():
    """ 
        Utility function to load surrogate models and associated data scalers from a file.

        Loads a set of trained surrogate models from a pickle file, or generates them from 
        surrogate_modeler.py. One model is loaded for each output variable. The models and
        scalers are loaded into separate lists and returned.

        The files from which the models and scalers are loaded from is set in the root config.

        Args:
            None

        Returns:
            surrogate_models: A list containing the loaded surrogate models.
            Y_scalers: A list of Scikit-Learn MinMaxScaler objects trained to scale the outputs
                       of the respective models in surrogate_models to their proper ranges.
    """
    surrogate_models = []
    if model_from_file is True:
        SM_out = "../SurrogateModeling/SM_outputs/"
        model_file = SM_out + config.data_title + "_surrogate_models.pkl"
        scaler_file = SM_out + config.data_title + "_datascalers.pkl"
        print "\nLoading surrogate models from %s" %model_file
        import pickle
        with open(model_file, 'r') as pfile:
            surrogate_models = pickle.load(pfile)
        with open(scaler_file, 'r') as pfile:
            Y_scalers = pickle.load(pfile)
    else:
        modeling_path = "../SurrogateModeling/"
        sys.path.append(modeling_path)
        import surrogate_modeler
        surrogate_models, Y_scalers = surrogate_modeler.main()
    print "Surrogate models: %d" %len(surrogate_models)
    print "Data scalers: %d" %len(Y_scalers)
    return surrogate_models, Y_scalers

def plot_S1(SAlist, SAtarget_names, showplot = True, saveplot = True, chart_type = 'pie'):
    """
        Make pie charts of the input sensitivity fractions for each analysis in the SA list passed in.

        Args:
            SAlist: List of SAData dictionaries. Required.

            SAtarget_names: List of Strings. Required. 
                Title for each SAData pie chart. Should be the descriptor names
                of the surrogate models.

            showplot: Boolean. Optional.
                Open the plot in a separate window.

            saveplot: Save the plot to file.

            chart_type: String.
                Type of chart to plot. Can choose between 'pie' (default) for a pie chart, or 'bar' for a bar chart.
                Bar charts not yet fully implemented.
        Returns:
            None. Plots a figure.
    """
    import matplotlib.pyplot as plt
    import matplotlib.colors as colors

    nplots = len(SAlist)
    ncols = 2
    nrows = int(math.ceil(nplots/ncols)) + 1

    cmap = plt.cm.jet
    colors = cmap(np.linspace(0., 1., len(config.features)))

    fig = plt.figure(num = 'S1 Sensitivities')

    for n, (SAData, target_name) in enumerate(izip(SAlist, config.targets)):
        ax = fig.add_subplot(nrows, 2 , n + 1)
        print SAData['S1']
        dat = [float(i) for i in SAData['S1']]

        print "sum:\n", np.sum(dat)
        if chart_type == 'pie':
            #ax.pie(SAData['S1'], labels = [name for name in config.features], colors=colors, autopct = '%1.1f%%', shadow = True, frame = False)
            ax.pie(SAData['S1'], colors=colors, autopct = '%1.1f%%', shadow = True, frame = False)
            ax.set_title(SAtarget_names[n])

        elif chart_type == 'bar':
            print [param['S1'] for param in SAlist]
            ind = np.arange(len(SAlist))
            width = 0.5
            ax.bar(ind, [param['S1'] for param in SAlist], width, color = 'r')

    if saveplot:
        fig.savefig('%s%s_S1.png' %(output_dir, config.data_title))
    else:
        plt.show()


def plot_ST(SAlist, SAtarget_names, savefig = True):
    import matplotlib.pyplot as plt
    import matplotlib.colors as colors
    nplots = len(SAlist)
    ncols = 2
    nrows = int(math.ceil(nplots/ncols)) + 1

    cmap = plt.cm.jet
    colors = cmap(np.linspace(0., 1., len(config.features)))

    fig = plt.figure(num = 'Total Sensitivities')

    for n, (SAData, target_name) in enumerate(izip(SAlist, config.targets)):
        ax = fig.add_subplot(nrows, 2 , n + 1)
        print SAData['ST']
        dat = [float(i) for i in SAData['ST']]
        print "sum:\n", np.sum(dat)

        #ax.pie(SAData['ST'], labels = [name for name in config.features], colors=colors, autopct = '%1.1f%%', shadow = True, frame = False)
        ax.pie(SAData['ST'], colors=colors, autopct = '%1.1f%%', shadow = True, frame = False)
        ax.set_title(SAtarget_names[n])
        ax.set_title(SAtarget_names[n])
    #plt.legend(labels = [name for name in config.features], loc = 0)
    if savefig == True:
        fig.savefig('%s%s_ST.png' %(output_dir, config.data_title))
    else:
        plt.show()

def plot_S1S2(SAlist, SAtarget_names, showplot = True, savefig = True):
    import matplotlib.pyplot as plt
    import matplotlib.colors as colors
    nplots = len(SAlist)
    ncols = 2
    nrows = int(math.ceil(nplots/ncols)) + 1

    cmap = plt.cm.viridis
    colors = cmap(np.linspace(0., 1., len(config.features)))

    fig = plt.figure(num = "Combined S1 and S2 Sensitivities")

    for n, (SAData, target_name) in enumerate(izip(SAlist, config.targets)):
        ax = fig.add_subplot(nrows, 2, n + 1)
        x = np.append(SAData['S1'], SAData['S2'])
        S1_labels = [name for name in config.features]
        S2_labels = ["%s/%s" %(param1, param2) for param1 in config.features for param2 in config.features]
        labels = np.append(S1_labels, S2_labels)

        # Go through and remove all but the 10 most significant parameters. Combine the rest into an "other" slice
        x = np.reshape(x,(len(x),1))
        labels = np.reshape(labels,(len(labels),1))
        wedges = np.hstack((x,labels))

        print "pre-sorted wedges:\n", wedges[:,0]
        print "pre-sorted labels:\n", wedges[:,1]

        sort_indices = np.argsort(wedges, axis=0)
        sorted_wedges = wedges[sort_indices[:,0]]

        sorted_wedges = sorted_wedges.T
        wedges = [float(i) for i in sorted_wedges[0,-10:]]
        labels = sorted_wedges[1,-10:]

        print "sorted wedges:\n", wedges
        print "sorted labels:\n", labels 

        print np.sum(wedges)
        other_proportion = 1.0 - np.sum(wedges)
        print "other: ", other_proportion
        wedges = np.append(wedges, other_proportion)
        labels = np.append(labels,'other')

        print "final wedges:\n", wedges
        print "final labels:\n", labels 

        ax.pie(wedges, labels = labels, colors = colors, autopct = '%1.1f%%', shadow=True, frame=False)
        ax.set_title(SAtarget_names[n])
    if savefig == True:
        fig.savefig('%s%s_S1_S2.png' %(output_dir, data_title))
    if showplot == True:
        plt.show()

def rm_NaN_from_array(inarray):
    shape = np.shape(inarray)
    nanarray = np.isnan(inarray)

    print inarray
    for m, row in enumerate(nanarray):
        for n, item in enumerate(row):
            if item == True:
                inarray[m,n] = 0.0
    return inarray


def run_sensitivity_analysis(n_samples = 1e4):
    """
        Generate Saltelli-sequence samples of model inputs and run variance-based Sobol sensitivity analysis on the models.

        Args:
            n_samples: Optional integer. Number of samples to generate for sensitivity analysis.

        Returns:
            SA_list: A list containing SAData dictionaries of the sensitivity analysis results.

    """
    # Load the parameter range data
    inData=[]
    with open(config.param_file,'rb') as f:
        for line in f:
            inData.append(line.rstrip('\n').split('\t'))

    # get the names of the parameters from the problem range definitions
    param_names = [inData[i][0] for i in range(0,len(inData))]
    print "param_names:\n", param_names

    #print np.shape(inData)
    #print len(inData)
    #print inData
    # Define the input dictionary for the sampling
    problem={'num_vars':len(inData),
             'names':[inData[i][0].strip() for i in range(len(inData))],
             'bounds':[[float(inData[i][1]),float(inData[i][2])] for i in range(0, len(inData))]}
    # Generate the set of samples to be run through the surrogate model
    if config.compute_second_order==True:
        k=2
    else:
        k=1
    param_list=saltelli.sample(problem,int(round(float(config.Nsamples)/(k*problem['num_vars']+2))),calc_second_order=config.compute_second_order)

    # Save the samples to a pickle file
    with open('%s%s_saltellisamples.pkl' %(output_dir, config.data_title), 'w') as pf:
        pickle.dump(param_list, pf)
    ###############################################################################
    #                   SURROGATE MODEL EVALUATION                                #
    ###############################################################################
    # Get a list of surrogate models for each parameter, and run sensitity analysis
    # on each model.
    model_list, Y_scalers = load_surrogate_models()

    SA_list = []

    for surrogatemodel, scaler, model_target_name in izip(model_list, Y_scalers, config.targets):
        print model_target_name
        print surrogatemodel
        # Scale the input samples
        data_scaler = preprocessing.MinMaxScaler(feature_range=(0,1)).fit(param_list)
        param_scaled = data_scaler.transform(param_list)

        # use the surrogate model to make predictions based on the generated sample paramters.
        # scale the predictions to their actual values using a MinMax scaler trained on the real
        # Y values.
        outData = surrogatemodel.predict(param_scaled)
        outData = scaler.inverse_transform(outData)

        ###############################################################################
        #
        # Generate the sensitivity analysis data
        if config.n_cores > 0:
            para = True
        else:
            para = False
        SAData=sobol.analyze(problem, outData, calc_second_order = config.compute_second_order, print_to_console = config.DEBUG, parallel = para, n_processors = config.n_cores)
        # Map NaNs in S2 data to 0.0
        if config.compute_second_order:
            SAData['S2'] = rm_NaN_from_array(SAData['S2'])

        print "SAData shape: ", np.shape(SAData)
        print SAData
        
        if config.DEBUG:
            # print the sensitivities by feature parameter to terminal
            print "{:<20}{:<20}{:<20}{:<20}{:<20}".format('param name', 'S1', 'S1_conf', 'ST', 'ST_conf')
            for param in range(0, len(param_names)):
                #print "%s:\t%f\t%f\t%f\t%f" %(param_names[param], SAData['S1'][param], SAData['S1_conf'][param], SAData['ST'][param], SAData['ST_conf'][param])
                print '{:<20}{:<20.3}{:<20.3}{:<20.3}{:<20.3}'.format(param_names[param], SAData['S1'][param], SAData['S1_conf'][param], SAData['ST'][param], SAData['ST_conf'][param])
        
        # write the sensitivities by feature parameter to a csv file with rows as the parameters and columns as the
        # sensitivities.
        # first, generate a unique timestamp-based filename for the output csv
        #tstamp_dt = dt.datetime.utcnow()
        #timestamp = "%d-%d-%d::%d:%d" %(tstamp_dt.year, tstamp_dt.month, tstamp_dt.day, tstamp_dt.hour, tstamp_dt.minute)
        outfile = "_SA_Results_%s" %model_target_name

        with open("%s%s%s.pkl" %(output_dir, config.data_title, outfile), 'w') as pfile:
            pickle.dump(SAData, pfile)
        
        with open("%s%s%s.csv" %(output_dir, config.data_title, outfile), 'w') as csvfile:
            writer = csv.writer(csvfile)
            if config.compute_second_order:
                header = ["param name","S1","S1_conf","S2","S2_conf","ST","ST_conf"]
            else:
                header = ["param name","S1","S1_conf","ST","ST_conf"]
            writer.writerow(header)
            for param in range(0, len(param_names)):
                if config.compute_second_order:
                    row = [param_names[param], SAData['S1'][param], SAData['S1_conf'][param], SAData['S2'][param], SAData['S2_conf'][param], SAData['ST'][param], SAData['ST_conf'][param]]
                else:
                    row = [param_names[param], SAData['S1'][param], SAData['S1_conf'][param], SAData['ST'][param], SAData['ST_conf'][param]]
                writer.writerow(row)

        SA_list.append(SAData)
    return SA_list

if __name__ == "__main__":
    #SA_list = run_sensitivity_analysis(config.Nsamples)
    with open('sample_SA_list.pkl', 'r') as pklf:
        SA_list = pickle.load(pklf)

    plot_S1(SA_list, SAtarget_names = config.targets, chart_type = 'bar')
    #plot_ST(SA_list, SAtarget_names = config.targets)
    #if config.compute_second_order:
        #plot_S1S2(SA_list, SAtarget_names = config.targets)